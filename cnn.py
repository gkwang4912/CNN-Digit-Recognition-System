import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
import re  
from PIL import Image

# **è¨­å®šè³‡æ–™å¤¾**
input_folder = "dataset_folder"  # åŸå§‹åœ–ç‰‡è³‡æ–™å¤¾
output_folder = "processed_images"  # åˆ‡å‰²å¾Œçš„åœ–ç‰‡å„²å­˜è³‡æ–™å¤¾
model_path = "digit_recognition_model.h5"  # æ¨¡å‹å­˜æª”ä½ç½®
os.makedirs(output_folder, exist_ok=True)  # ç¢ºä¿è¼¸å‡ºè³‡æ–™å¤¾å­˜åœ¨

# **å»ºç«‹ CNN æ¨¡å‹**
print("ğŸ†• å»ºç«‹æ–° CNN æ¨¡å‹...")
model = models.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(10, activation='softmax')  
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

processed_count = 0  # è¨˜éŒ„å·²è™•ç†çš„åœ–ç‰‡æ•¸é‡
image_index = 0  # è¨˜éŒ„ç›®å‰è™•ç†åˆ°çš„ç¬¬å¹¾å¼µåœ–ç‰‡

# **å‡½å¼ï¼šåˆ‡å‰²åœ–ç‰‡**
def split_image(image_path, output_folder):
    start, end, num_slices = 7, 83, 5  
    image = Image.open(image_path)
    width, height = image.size

    crop_width = end - start
    slice_width = crop_width // num_slices

    filename = os.path.basename(image_path)
    name_parts = filename.split("_")

    image_time = f"{name_parts[0]}_{name_parts[1]}_"
    image_name = os.path.splitext(name_parts[2])[0]  

    output_files = []  

    for i in range(num_slices):
        left = start + i * slice_width
        right = left + slice_width if i < num_slices - 1 else end
        
        cropped = image.crop((left, 0, right, height))
        suffix = image_name[i] if i < len(image_name) else str(i)
        save_path = os.path.join(output_folder, f"{i}_{image_time}{suffix}.jpg")
        cropped.save(save_path)
        output_files.append(save_path)

    return output_files  

# **é€å¼µè™•ç†ä¸¦è¨“ç·´**
for filename in os.listdir(input_folder):
    if filename.endswith(".jpg") or filename.endswith(".png"):
        image_index += 1  # è¨˜éŒ„ç•¶å‰è™•ç†çš„ç¬¬å¹¾å¼µåœ–ç‰‡
        print(f"ğŸ“· æ­£åœ¨è™•ç†ç¬¬ {image_index} å¼µåœ–ç‰‡",end="")
        
        image_path = os.path.join(input_folder, filename)
        cropped_files = split_image(image_path, output_folder)  

        image_data = []
        labels = []
        
        for cropped_file in cropped_files:
            match = re.findall(r'(\d+)', cropped_file)  
            if match:
                label = int(match[-1])  
                img = cv2.imread(cropped_file, cv2.IMREAD_GRAYSCALE)  
                img = cv2.resize(img, (28, 28))  
                img = img / 255.0  
                image_data.append(img)
                labels.append(label)
        
        if image_data:
            image_data = np.array(image_data).reshape(-1, 28, 28, 1)  
            labels = np.array(labels)

            model.fit(image_data, labels, epochs=2, batch_size=5, verbose=0)  # éš±è—è©³ç´°è¼¸å‡º
            processed_count += len(image_data)  

            print(f"âœ… å·²è¨“ç·´ {processed_count} å¼µåˆ‡å‰²å¾Œçš„åœ–ç‰‡")

# **å­˜æª”ï¼ˆä¸åŒ…å« optimizerï¼‰**
model.save(model_path, include_optimizer=False)  
print(f"ğŸ’¾ è¨“ç·´å®Œæˆï¼Œæ¨¡å‹å·²å„²å­˜è‡³ {model_path}ï¼ˆä¸åŒ…å« optimizerï¼‰")
print(f"ğŸ“Š ç¸½å…±è™•ç†ä¸¦è¨“ç·´äº† {processed_count} å¼µåœ–ç‰‡ï¼")
