import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt
from matplotlib import rcParams  # è¨­å®šå…¨åŸŸå­—å‹
from PIL import Image

# è¨­å®šå…¨åŸŸå­—å‹
rcParams['font.family'] = 'Microsoft JhengHei'

# è¨­å®šè®Šæ•¸
model_path = "digit_recognition_model.h5"  # å·²è¨“ç·´çš„æ¨¡å‹
test_image_path = "20250219_082720_97919.jpg"  # æ¸¬è©¦åœ–ç‰‡
output_folder = "split_images"  # å­˜æ”¾åˆ‡å‰²å¾Œåœ–ç‰‡çš„è³‡æ–™å¤¾

# ç¢ºä¿æ¨¡å‹å­˜åœ¨
if not os.path.exists(model_path):
    raise FileNotFoundError("âŒ æ‰¾ä¸åˆ°æ¨¡å‹ï¼Œè«‹å…ˆè¨“ç·´ä¸¦å­˜æª” digit_recognition_model.h5")

# è¼‰å…¥æ¨¡å‹
print("ğŸ”„ è¼‰å…¥æ¨¡å‹ä¸­...")
model = load_model(model_path)
print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆï¼")

# å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

# åœ–ç‰‡é è™•ç†å‡½å¼
def preprocess_image(image_path):
    image = Image.open(image_path).convert("L")  # è½‰æ›æˆç°éš
    image = image.resize((28, 28))  # èª¿æ•´ç‚º 28x28
    image = np.array(image) / 255.0  # æ­£è¦åŒ–
    image = image.reshape(1, 28, 28, 1)  # èª¿æ•´å½¢ç‹€ç¬¦åˆ CNN è¼¸å…¥
    return image

# åœ–ç‰‡åˆ‡å‰²å‡½å¼
def split_image(image_path, output_folder):
    start, end, num_slices = 7, 83, 5  # è¨­å®šåˆ‡å‰²ç¯„åœèˆ‡æ•¸é‡
    image = Image.open(image_path)
    width, height = image.size

    crop_width = end - start
    slice_width = crop_width // num_slices

    filename = os.path.basename(image_path)
    name_parts = filename.split("_")

    image_time = f"{name_parts[0]}_{name_parts[1]}_"
    image_name = os.path.splitext(name_parts[2])[0]  # å–æª”åæ•¸å­—éƒ¨åˆ†

    output_files = []  

    for i in range(num_slices):
        left = start + i * slice_width
        right = left + slice_width if i < num_slices - 1 else end
        
        cropped = image.crop((left, 0, right, height))
        suffix = image_name[i] if i < len(image_name) else str(i)  # å‘½å
        save_path = os.path.join(output_folder, f"{i}_{image_time}{suffix}.jpg")
        cropped.save(save_path)
        output_files.append(save_path)

    return output_files    

# åˆ‡å‰²åœ–ç‰‡
if not os.path.exists(test_image_path):
    raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ¸¬è©¦åœ–ç‰‡ï¼š{test_image_path}")

print("ğŸ”„ æ­£åœ¨åˆ‡å‰²åœ–ç‰‡...")
split_images = split_image(test_image_path, output_folder)
print(f"âœ… åœ–ç‰‡å·²åˆ‡å‰²ç‚º {len(split_images)} ç‰‡ï¼")

# ä¾åºé€²è¡Œé æ¸¬
predicted_numbers = []
for i, img_path in enumerate(split_images):
    image = preprocess_image(img_path)
    prediction = model.predict(image)
    predicted_label = np.argmax(prediction)  # å–å¾—æœ€å¯èƒ½çš„æ•¸å­—
    confidence = np.max(prediction)  # å–å¾—æœ€å¤§ä¿¡å¿ƒå€¼

    # é¡¯ç¤ºçµæœ
    plt.subplot(1, len(split_images), i + 1)
    plt.imshow(image.reshape(28, 28), cmap="gray")
    plt.title(f"{predicted_label} ({confidence:.2f})")
    plt.axis("off")

    predicted_numbers.append(str(predicted_label))

# é¡¯ç¤ºæ‰€æœ‰åˆ‡å‰²åœ–é æ¸¬çµæœ
plt.show()

# çµ„åˆæ‰€æœ‰é æ¸¬æ•¸å­—
final_number = "".join(predicted_numbers)
print(f"ğŸ“Š æœ€çµ‚é æ¸¬çµæœï¼š{final_number}")
